/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Resource allocations for each process
    Nodes: 384 CPUs, ~1.5 TB RAM each (shared)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// Helper function: cap resources at user-defined max
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "WARNING: Max memory '${params.max_memory}' is not valid - using default"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "WARNING: Max time '${params.max_time}' is not valid - using default"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "WARNING: Max cpus '${params.max_cpus}' is not valid - using default"
            return obj
        }
    }
}

process {
   // --- Defaults ---
    cpus          = { check_max( 1, 'cpus' ) }
    memory        = { check_max( 4.GB, 'memory' ) }
    time          = { check_max( 1.h, 'time' ) }

   // Retry on OOM / SLURM memory-kill / NFS SIGBUS exit codes
    errorStrategy = { task.exitStatus in [104, 134, 135, 137, 139, 140, 143, 247] ? 'retry' : 'finish' }
    maxRetries    = 2

   // -- SortMeRNA ---------------------------------------------------------
    withName: 'SORTMERNA_INDEX' {
        cpus   = { check_max( 4, 'cpus' ) }
        memory = { check_max( 16.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h, 'time' ) }
    }
    withName: 'SORTMERNA' {
        cpus      = { check_max( 32, 'cpus' ) }
        memory    = { check_max( 64.GB * task.attempt, 'memory' ) }
        time      = { check_max( 8.h * task.attempt, 'time' ) }
        maxForks  = 15
    }

   // -- MMseqs2 nucleotide dedup ------------------------------------------
    withName: 'MMSEQS2_CLUSTER_NT' {
        cpus     = { check_max( 32, 'cpus' ) }
        memory   = { check_max( 128.GB * task.attempt, 'memory' ) }
        time     = { check_max( 4.h * task.attempt, 'time' ) }
        ext.args = { "--min-seq-id ${params.mmseqs2_nt_id} -c ${params.mmseqs2_nt_cov} --cov-mode 1" }
    }

   // -- Salmon initial (transcript-level, with --dumpEq for Corset) ------
    withName: 'SALMON_INDEX_INITIAL' {
        cpus     = { check_max( 8, 'cpus' ) }
        memory   = { check_max( 100.GB * task.attempt, 'memory' ) }
        time     = { check_max( 4.h * task.attempt, 'time' ) }
        ext.args = '--keepDuplicates'
    }
    withName: 'SALMON_QUANT_INITIAL' {
        cpus     = { check_max( 8, 'cpus' ) }
        memory   = { check_max( 64.GB * task.attempt, 'memory' ) }
        time     = { check_max( 8.h * task.attempt, 'time' ) }
        ext.args = '--hardFilter --dumpEq'
    }

   // -- Corset + Lace -----------------------------------------------------
    withName: 'CORSET' {
        cpus       = { check_max( 1, 'cpus' ) }
        memory     = { check_max( 32.GB * task.attempt, 'memory' ) }
        time       = { check_max( 2.h * task.attempt, 'time' ) }
        publishDir = [ path: "${params.outdir}/clustering", mode: 'copy' ]
    }
    withName: 'LACE' {
        cpus       = { check_max( 8, 'cpus' ) }
        memory     = { check_max( 64.GB * task.attempt, 'memory' ) }
        time       = { check_max( 8.h * task.attempt, 'time' ) }
        publishDir = [ path: "${params.outdir}/supertranscripts", mode: 'copy' ]
    }

   // -- Taxonomy filter (single process, DB copied to node-local SSD) ---------
    withName: 'MMSEQS2_TAXONOMY' {
        cpus       = { check_max( 32, 'cpus' ) }
        memory     = { check_max( [300.GB, 400.GB, 500.GB][task.attempt - 1], 'memory' ) }
        time       = { check_max( 24.h * task.attempt, 'time' ) }
        publishDir = [ path: "${params.outdir}/taxonomy", mode: 'copy' ]
    }

   // -- Frameshift correction (single process, DB copied to node-local SSD) ----
    withName: 'DIAMOND_BLASTX' {
        cpus   = { check_max( 32, 'cpus' ) }
        memory = { check_max( 32.GB * task.attempt, 'memory' ) }
        time   = { check_max( 8.h * task.attempt, 'time' ) }
    }
    withName: 'CORRECT_FRAMESHIFTS' {
        cpus       = { check_max( 1, 'cpus' ) }
        memory     = { check_max( 8.GB * task.attempt, 'memory' ) }
        time       = { check_max( 1.h, 'time' ) }
        publishDir = [ path: "${params.outdir}/frameshift_correction", mode: 'copy', pattern: 'frameshift_stats.txt' ]
    }

   // -- TD2 ORF prediction -----------------------------------------------
    withName: 'TD2_LONGORFS' {
        cpus     = { check_max( 8, 'cpus' ) }
        memory   = { check_max( 16.GB * task.attempt, 'memory' ) }
        time     = { check_max( 2.h * task.attempt, 'time' ) }
        ext.args = { (params.td2_strand_specific ? '-S ' : '') + "-m ${params.td2_min_orf_length}" }
    }
    withName: 'TD2_PREDICT' {
        cpus   = { check_max( 1, 'cpus' ) }
        memory = { check_max( 8.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h * task.attempt, 'time' ) }
    }

   // -- MMseqs2 homology searches (chunked) --------------------------------

   // -- Best ORF selection -----------------------------------------------
    withName: 'SELECT_BEST_ORF' {
        cpus       = { check_max( 1, 'cpus' ) }
        memory     = { check_max( 4.GB * task.attempt, 'memory' ) }
        time       = { check_max( 30.min, 'time' ) }
        publishDir = [
            [ path: "${params.outdir}/proteins",   mode: 'copy', pattern: '*.faa' ],
            [ path: "${params.outdir}/annotation", mode: 'copy', pattern: '*.gff3' ],
            [ path: "${params.outdir}/annotation", mode: 'copy', pattern: '*.tsv' ]
        ]
    }

   // -- Salmon final (gene-level SuperTranscripts) -----------------------
    withName: 'SALMON_INDEX_FINAL' {
        cpus   = { check_max( 8, 'cpus' ) }
        memory = { check_max( 32.GB * task.attempt, 'memory' ) }
        time   = { check_max( 2.h * task.attempt, 'time' ) }
    }
    withName: 'SALMON_QUANT_FINAL' {
        cpus       = { check_max( 8, 'cpus' ) }
        memory     = { check_max( 32.GB * task.attempt, 'memory' ) }
        time       = { check_max( 8.h * task.attempt, 'time' ) }
        ext.args   = '--rangeFactorizationBins 4'
        publishDir = [ path: "${params.outdir}/salmon_final", mode: 'copy' ]
    }

   // -- Validation & QC -------------------------------------------------
    withName: 'VALIDATE_IDS' {
        cpus   = { check_max( 1, 'cpus' ) }
        memory = { check_max( 2.GB, 'memory' ) }
        time   = { check_max( 10.min, 'time' ) }
    }
    withName: 'BUSCO_QC' {
        cpus       = { check_max( 16, 'cpus' ) }
        memory     = { check_max( 32.GB * task.attempt, 'memory' ) }
        time       = { check_max( 4.h * task.attempt, 'time' ) }
        ext.args   = { "-l ${params.busco_lineage}" }
        publishDir = [ path: "${params.outdir}/qc", mode: 'copy' ]
    }

   // -- Functional annotation -------------------------------------------
    withName: 'TRANSANNOT' {
        cpus       = { check_max( 16, 'cpus' ) }
        memory     = { check_max( 64.GB * task.attempt, 'memory' ) }
        time       = { check_max( 8.h * task.attempt, 'time' ) }
        publishDir = [ path: "${params.outdir}/transannot", mode: 'copy' ]
    }

   // -- Report ----------------------------------------------------------
    withName: 'THINNING_REPORT' {
        cpus       = { check_max( 1, 'cpus' ) }
        memory     = { check_max( 4.GB, 'memory' ) }
        time       = { check_max( 30.min, 'time' ) }
        publishDir = [ path: "${params.outdir}", mode: 'copy' ]
    }

   // ======================================================================
   //  Chunked processes (data-level parallelization)
   // ======================================================================

   // -- MMSEQS2_SEARCH chunked (5-8x speedup via parallelization) --------
    withName: 'SPLIT_ORFS' {
        cpus           = { check_max( 1, 'cpus' ) }
        memory         = { check_max( 4.GB, 'memory' ) }
        time           = { check_max( 10.min, 'time' ) }
        ext.chunk_size = { params.search_orf_chunk_size ?: 40000 }
    }
    withName: 'MMSEQS2_SEARCH_CHUNK' {
        cpus     = { check_max( 16, 'cpus' ) }
        memory   = { check_max( [80.GB, 120.GB, 160.GB][task.attempt - 1], 'memory' ) }
        time     = { check_max( 2.h * task.attempt, 'time' ) }
        maxForks = params.max_parallel_search_chunks
        ext.args = { "-s ${params.mmseqs2_search_sens}" }
    }
    withName: 'MERGE_M8_RESULTS' {
        cpus       = { check_max( 2, 'cpus' ) }
        memory     = { check_max( 8.GB, 'memory' ) }
        time       = { check_max( 30.min, 'time' ) }
        publishDir = [ path: "${params.outdir}/mmseqs2_search", mode: 'copy', pattern: '*.m8' ]
    }

}
